# ü§ñ –ó–∞–ø—É—Å–∫ AI (LLaMA) –¥–ª—è —É–º–Ω–æ–≥–æ —á–∞—Ç–∞

## ‚ùó –í–ê–ñ–ù–û: –ë–µ–∑ —ç—Ç–æ–≥–æ AI —á–∞—Ç –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ!

AI —á–∞—Ç –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å **LLaMA 3 8B** –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤.

---

## üìã –ß—Ç–æ –Ω—É–∂–Ω–æ:

1. ‚úÖ **–ú–æ–¥–µ–ª—å —É–∂–µ —Å–∫–∞—á–∞–Ω–∞**: `models/llama-3-8b-instruct-q4_k_m.gguf` (–µ—Å—Ç—å –≤ –ø—Ä–æ–µ–∫—Ç–µ)
2. ‚úÖ **Docker** —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
3. ‚úÖ **Backend** –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ LLaMA

---

## üöÄ –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å LLaMA:

### –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ (5.249.160.54):

```bash
# 1. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ—Å—å –∫ —Å–µ—Ä–≤–µ—Ä—É
ssh root@5.249.160.54

# 2. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –≤ –ø–∞–ø–∫—É –ø—Ä–æ–µ–∫—Ç–∞
cd /root/lonestar-chat  # –∏–ª–∏ –≥–¥–µ —É –≤–∞—Å –ø—Ä–æ–µ–∫—Ç

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –¢–û–õ–¨–ö–û LLaMA –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
docker-compose up -d llama

# 4. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å
docker ps | grep llama

# –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å:
# lonestar-llama   Up X minutes   0.0.0.0:8081->8080/tcp

# 5. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
docker logs -f lonestar-llama

# 6. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ health
curl http://localhost:8081/health
```

---

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã:

### –¢–µ—Å—Ç 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ API –Ω–∞–ø—Ä—è–º—É—é
```bash
curl -X POST http://localhost:8081/completion \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
    "temperature": 0.7,
    "max_tokens": 100
  }'
```

### –¢–µ—Å—Ç 2: –ß–µ—Ä–µ–∑ Backend
```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ
curl -X POST https://5.249.160.54/api/ai/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{"message": "–ü—Ä–∏–≤–µ—Ç!"}'
```

---

## üêõ –ï—Å–ª–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç:

### –ü—Ä–æ–±–ª–µ–º–∞: "Failed to connect to AI service"
**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —á—Ç–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –∑–∞–ø—É—â–µ–Ω
docker ps | grep llama

# –ï—Å–ª–∏ –Ω–µ—Ç - –∑–∞–ø—É—Å—Ç–∏—Ç–µ
docker-compose up -d llama

# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏
docker logs lonestar-llama
```

### –ü—Ä–æ–±–ª–µ–º–∞: "Out of memory"
**–†–µ—à–µ–Ω–∏–µ:** –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –º–∏–Ω–∏–º—É–º 4-6GB RAM
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–∞–º—è—Ç—å
free -h

# –ï—Å–ª–∏ –º–∞–ª–æ - –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥—Ä—É–≥–∏–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã
docker stop lonestar-meilisearch  # –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–π
```

### –ü—Ä–æ–±–ª–µ–º–∞: "Model not found"
**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
ls -lh models/llama-3-8b-instruct-q4_k_m.gguf

# –ï—Å–ª–∏ –Ω–µ—Ç - —Å–∫–∞—á–∞–π—Ç–µ
cd models
wget https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf \
  -O llama-3-8b-instruct-q4_k_m.gguf
```

---

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:

–í —Ñ–∞–π–ª–µ `.env` –∏–ª–∏ `docker-compose.yml`:

```bash
# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 8)
LLAMA_THREADS=4  # –£–º–µ–Ω—å—à–∏—Ç–µ –µ—Å–ª–∏ CPU —Å–ª–∞–±—ã–π

# –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4096)
LLAMA_CONTEXT_SIZE=2048  # –£–º–µ–Ω—å—à–∏—Ç–µ –µ—Å–ª–∏ –º–∞–ª–æ RAM
```

–ü–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è:
```bash
docker-compose up -d llama --force-recreate
```

---

## üìä –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–µ—Ä–≤–µ—Ä—É:

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ú–∏–Ω–∏–º—É–º | –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è |
|-----------|---------|---------------|
| **RAM**   | 6 GB    | 8 GB          |
| **CPU**   | 4 —è–¥—Ä–∞  | 8 —è–¥–µ—Ä        |
| **–î–∏—Å–∫** | 5 GB    | 10 GB         |

---

## üîÑ Fallback —Ä–µ–∂–∏–º:

–ï—Å–ª–∏ LLaMA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, AI —á–∞—Ç –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ **fallback —Ä–µ–∂–∏–º–µ**:
- ‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∫—Ä–∞—à–Ω–µ—Ç—Å—è
- ‚úÖ –ü–æ–∫–∞–∂–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —á—Ç–æ AI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
- ‚úÖ –ü–æ–ø—Ä–æ—Å–∏—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä

**–ü—Ä–∏–º–µ—Ä fallback –æ—Ç–≤–µ—Ç–∞:**
> "–ü–æ–ª—É—á–µ–Ω –≤–∞—à –≤–æ–ø—Ä–æ—Å: '–ü—Ä–∏–≤–µ—Ç'. AI –º–æ–¥–µ–ª—å LLaMA —Å–µ–π—á–∞—Å –Ω–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç–∞—Ç—É—Å Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –∫–æ–º–∞–Ω–¥–æ–π: docker ps | grep llama"

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π —Å–ø–∏—Å–æ–∫:

- [ ] Docker —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
- [ ] –ú–æ–¥–µ–ª—å `llama-3-8b-instruct-q4_k_m.gguf` —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –≤ `models/`
- [ ] –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä `lonestar-llama` –∑–∞–ø—É—â–µ–Ω (`docker ps`)
- [ ] Health check –ø—Ä–æ—Ö–æ–¥–∏—Ç (`curl http://localhost:8081/health`)
- [ ] Backend –º–æ–∂–µ—Ç –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LLaMA
- [ ] AI —á–∞—Ç –≤ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –æ—Ç–≤–µ—á–∞–µ—Ç —É–º–Ω–æ (–Ω–µ fallback)

---

## üéØ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–æ–¥–Ω–∞ –∫–æ–º–∞–Ω–¥–∞):

```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ 5.249.160.54
cd /root/lonestar-chat && docker-compose up -d llama && docker logs -f lonestar-llama
```

---

## üì± –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:

1. –û—Ç–∫—Ä–æ–π—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ iPhone
2. –í–æ–π–¥–∏—Ç–µ –∫–∞–∫ admin/admin
3. –û—Ç–∫—Ä–æ–π—Ç–µ AI Chat (–∏–∫–æ–Ω–∫–∞ —Ä–æ–±–æ—Ç–∞)
4. –ù–∞–ø–∏—à–∏—Ç–µ: "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?"
5. –ñ–¥–∏—Ç–µ –æ—Ç–≤–µ—Ç (10-30 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–≤—ã–π —Ä–∞–∑)

**–ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ:**
- ‚úÖ –û—Ç–≤–µ—Ç –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π –∏ —Ä–∞–∑–Ω—ã–π –∫–∞–∂–¥—ã–π —Ä–∞–∑
- ‚úÖ –ú–æ–¥–µ–ª—å –æ—Ç–≤–µ—á–∞–µ—Ç –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É –≤–æ–ø—Ä–æ—Å–∞

**–ï—Å–ª–∏ fallback —Ä–µ–∂–∏–º:**
- ‚ö†Ô∏è –û—Ç–≤–µ—Ç –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å "AI —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
- ‚ö†Ô∏è –ù—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä

---

## üîó –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏:

- LLaMA.cpp: https://github.com/ggerganov/llama.cpp
- –ú–æ–¥–µ–ª–∏: https://huggingface.co/TheBloke
- Docker Compose docs: https://docs.docker.com/compose/

---

**–ê–≤—Ç–æ—Ä:** GitHub Copilot  
**–î–∞—Ç–∞:** 6 –æ–∫—Ç—è–±—Ä—è 2025
